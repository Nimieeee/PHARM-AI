#!/usr/bin/env python3
"""
Debug script to test the complete message flow in PharmGPT
"""

import os
import asyncio
import logging
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

async def test_api_keys():
    """Test API key configuration and connectivity."""
    logger.info("ğŸ”‘ Testing API key configuration...")
    
    # Check environment variables
    groq_key = os.environ.get("GROQ_API_KEY")
    openrouter_key = os.environ.get("OPENROUTER_API_KEY")
    
    logger.info(f"GROQ_API_KEY: {'âœ… Set' if groq_key else 'âŒ Missing'}")
    logger.info(f"OPENROUTER_API_KEY: {'âœ… Set' if openrouter_key else 'âŒ Missing'}")
    
    if not groq_key or not openrouter_key:
        logger.error("âŒ API keys are missing!")
        return False
    
    # Test API connections
    try:
        from openai_client import test_api_connection
        
        # Test Groq API
        groq_model = "meta-llama/llama-4-maverick-17b-128e-instruct"
        groq_works = test_api_connection(groq_model)
        logger.info(f"Groq API ({groq_model}): {'âœ… Working' if groq_works else 'âŒ Failed'}")
        
        # Test OpenRouter API
        openrouter_model = "openrouter/sonoma-sky-alpha"
        openrouter_works = test_api_connection(openrouter_model)
        logger.info(f"OpenRouter API ({openrouter_model}): {'âœ… Working' if openrouter_works else 'âŒ Failed'}")
        
        return groq_works or openrouter_works
        
    except Exception as e:
        logger.error(f"âŒ Error testing API connections: {e}")
        return False

async def test_database_connection():
    """Test database connection and user lookup."""
    logger.info("ğŸ—„ï¸ Testing database connection...")
    
    try:
        from services.user_service import user_service
        
        # Test user lookup
        test_user_id = "e4443c52948edad6132f34b6378a9901"
        user = await user_service.get_user_by_id(test_user_id)
        
        if user:
            logger.info(f"âœ… Database connection working - Found user: {user.get('username')}")
            return True, user
        else:
            logger.error(f"âŒ User not found: {test_user_id}")
            return False, None
            
    except Exception as e:
        logger.error(f"âŒ Database connection failed: {e}")
        return False, None

async def test_conversation_creation():
    """Test conversation creation."""
    logger.info("ğŸ’¬ Testing conversation creation...")
    
    try:
        from services.conversation_service import conversation_service
        
        # Get test user
        db_works, user = await test_database_connection()
        if not db_works or not user:
            logger.error("âŒ Cannot test conversation creation - database issues")
            return False, None
        
        # Create test conversation
        conversation_id = await conversation_service.create_conversation(
            user['id'], 
            "Debug Test Conversation", 
            "meta-llama/llama-4-maverick-17b-128e-instruct"
        )
        
        if conversation_id:
            logger.info(f"âœ… Conversation created successfully: {conversation_id}")
            return True, conversation_id
        else:
            logger.error("âŒ Failed to create conversation")
            return False, None
            
    except Exception as e:
        logger.error(f"âŒ Conversation creation failed: {e}")
        return False, None

async def test_message_addition():
    """Test adding messages to conversation."""
    logger.info("ğŸ“ Testing message addition...")
    
    try:
        from services.conversation_service import conversation_service
        
        # Get test user and conversation
        db_works, user = await test_database_connection()
        if not db_works or not user:
            logger.error("âŒ Cannot test message addition - database issues")
            return False
        
        conv_works, conversation_id = await test_conversation_creation()
        if not conv_works or not conversation_id:
            logger.error("âŒ Cannot test message addition - conversation creation failed")
            return False
        
        # Test adding user message
        test_message = {
            "role": "user",
            "content": "Hello, this is a test message",
            "timestamp": "2024-01-01T00:00:00Z"
        }
        
        success = await conversation_service.add_message(
            user['id'],
            conversation_id,
            test_message
        )
        
        if success:
            logger.info("âœ… Message added successfully")
            
            # Test adding assistant message
            assistant_message = {
                "role": "assistant", 
                "content": "Hello! This is a test response.",
                "timestamp": "2024-01-01T00:00:01Z"
            }
            
            success2 = await conversation_service.add_message(
                user['id'],
                conversation_id,
                assistant_message
            )
            
            if success2:
                logger.info("âœ… Assistant message added successfully")
                return True
            else:
                logger.error("âŒ Failed to add assistant message")
                return False
        else:
            logger.error("âŒ Failed to add user message")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Message addition failed: {e}")
        return False

async def test_ai_response_generation():
    """Test AI response generation."""
    logger.info("ğŸ¤– Testing AI response generation...")
    
    try:
        from openai_client import chat_completion
        
        # Test message
        test_messages = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "Say hello in exactly 5 words."}
        ]
        
        # Test with Groq model
        try:
            groq_model = "meta-llama/llama-4-maverick-17b-128e-instruct"
            response = chat_completion(groq_model, test_messages)
            logger.info(f"âœ… Groq response: {response[:100]}...")
            return True
        except Exception as groq_error:
            logger.error(f"âŒ Groq failed: {groq_error}")
            
            # Try OpenRouter as fallback
            try:
                openrouter_model = "openrouter/sonoma-sky-alpha"
                response = chat_completion(openrouter_model, test_messages)
                logger.info(f"âœ… OpenRouter response: {response[:100]}...")
                return True
            except Exception as or_error:
                logger.error(f"âŒ OpenRouter also failed: {or_error}")
                return False
                
    except Exception as e:
        logger.error(f"âŒ AI response generation failed: {e}")
        return False

async def test_streaming_response():
    """Test streaming AI response."""
    logger.info("ğŸ“¡ Testing streaming response...")
    
    try:
        from openai_client import chat_completion_stream
        
        test_messages = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": "Count from 1 to 5, one number per line."}
        ]
        
        # Test streaming with Groq
        try:
            groq_model = "meta-llama/llama-4-maverick-17b-128e-instruct"
            response_chunks = []
            
            for chunk in chat_completion_stream(groq_model, test_messages):
                response_chunks.append(chunk)
                if len(response_chunks) > 10:  # Limit for testing
                    break
            
            full_response = ''.join(response_chunks)
            logger.info(f"âœ… Streaming response: {full_response[:100]}...")
            return True
            
        except Exception as stream_error:
            logger.error(f"âŒ Streaming failed: {stream_error}")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Streaming test failed: {e}")
        return False

async def run_comprehensive_test():
    """Run all tests in sequence."""
    logger.info("ğŸš€ Starting comprehensive message flow test...")
    
    results = {}
    
    # Test 1: API Keys
    results['api_keys'] = await test_api_keys()
    
    # Test 2: Database
    results['database'] = (await test_database_connection())[0]
    
    # Test 3: Conversation Creation
    results['conversation'] = (await test_conversation_creation())[0]
    
    # Test 4: Message Addition
    results['messages'] = await test_message_addition()
    
    # Test 5: AI Response
    results['ai_response'] = await test_ai_response_generation()
    
    # Test 6: Streaming
    results['streaming'] = await test_streaming_response()
    
    # Summary
    logger.info("ğŸ“Š Test Results Summary:")
    for test_name, result in results.items():
        status = "âœ… PASS" if result else "âŒ FAIL"
        logger.info(f"  {test_name}: {status}")
    
    # Overall result
    all_passed = all(results.values())
    logger.info(f"ğŸ¯ Overall Result: {'âœ… ALL TESTS PASSED' if all_passed else 'âŒ SOME TESTS FAILED'}")
    
    if not all_passed:
        logger.info("ğŸ’¡ Troubleshooting suggestions:")
        if not results['api_keys']:
            logger.info("  - Check API keys in .env file")
        if not results['database']:
            logger.info("  - Check Supabase connection and user data")
        if not results['conversation']:
            logger.info("  - Check conversation service and database schema")
        if not results['messages']:
            logger.info("  - Check message storage and RLS policies")
        if not results['ai_response']:
            logger.info("  - Check API connectivity and model availability")
        if not results['streaming']:
            logger.info("  - Check streaming implementation and network")
    
    return all_passed

def main():
    """Main function."""
    logger.info("ğŸ§ª PharmGPT Message Flow Debug Tool")
    logger.info("=" * 50)
    
    # Run async tests
    result = asyncio.run(run_comprehensive_test())
    
    logger.info("=" * 50)
    logger.info(f"ğŸ Debug session completed: {'SUCCESS' if result else 'ISSUES FOUND'}")

if __name__ == "__main__":
    main()